{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg8-JrfjrAT7"
   },
   "source": [
    "# First Modification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "TqmH4fTkmMdo",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "541f12f1-42b6-49b5-a714-f44603732954"
   },
   "source": "!pip install -U google-generativeai google-genai google-adk",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YevT71Otmf9y",
    "outputId": "58936c3d-6f5e-4fde-a3a4-ce3665266755"
   },
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "try:\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "\n",
    "    print(\"API Key configured successfully!\")\n",
    "    print(f\"Using Model: {MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(\"ERROR: Could not load GOOGLE_API_KEY from Colab.\")\n",
    "    print(\"Add it in: Runtime → Secrets → GOOGLE_API_KEY\")\n",
    "    print(\"Details:\", e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7suGRthZnCwY",
    "outputId": "a5a1ecbd-1eb4-4639-81dc-1f73906f5c1f"
   },
   "source": [
    "jsf_analyzer = Agent(\n",
    "    name=\"JSF_Analyzer\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"\"\"\n",
    "        You are a JSF component analysis expert.\n",
    "\n",
    "        INPUT: A JSF component tag (e.g., <p:commandButton>, <p:dataTable>, <h:inputText>)\n",
    "\n",
    "        TASK:\n",
    "        - Identify what the JSF component does\n",
    "        - Extract attributes (value, action, update, rendered, etc.)\n",
    "        - Explain AJAX behavior if present\n",
    "        - Explain what server-side bean method will run\n",
    "        - Explain what UI parts will update\n",
    "\n",
    "        OUTPUT FORMAT (IMPORTANT):\n",
    "        Return your analysis as structured bullet points.\n",
    "    \"\"\",\n",
    "    tools=[google_search],              # optional but helpful\n",
    "    output_key=\"jsf_analysis\"\n",
    ")\n",
    "\n",
    "print(\"JSF Analyzer Agent Created\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mt2lRajcq04Y",
    "outputId": "ed1d5f3d-c5f8-4905-c7f2-d5b47e4ed4c0"
   },
   "source": [
    "angular_architect = Agent(\n",
    "    name=\"Angular_Migration_Architect\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"\"\"\n",
    "        You are an Angular migration specialist.\n",
    "\n",
    "        You will receive JSF analysis in this variable:\n",
    "        {jsf_analysis}\n",
    "\n",
    "        TASK:\n",
    "        - Convert the JSF component into Angular architecture\n",
    "        - Specify:\n",
    "            - Angular component structure\n",
    "            - .html template (rewrite)\n",
    "            - .ts logic (methods, services)\n",
    "            - .css ideas\n",
    "        - Explain how AJAX behavior maps to Angular:\n",
    "            - update=\"...\" → Angular state update\n",
    "            - action=\"#{bean.method}\" → Angular service call\n",
    "            - rendered → *ngIf\n",
    "            - disabled → [disabled]\n",
    "            - icon → Angular Material or custom css-icon\n",
    "\n",
    "        OUTPUT FORMAT:\n",
    "        Provide a clean and detailed Angular migration plan.\n",
    "    \"\"\",\n",
    "    output_key=\"angular_plan\"\n",
    ")\n",
    "\n",
    "print(\"Angular Architect Agent Created\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VL0ZisefFTeL"
   },
   "source": [
    "migration_pipeline = SequentialAgent(\n",
    "    name=\"JSF_to_Angular_Pipeline\",\n",
    "    sub_agents=[\n",
    "        jsf_analyzer,\n",
    "        angular_architect\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "D7bI2PkyLjFJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a08c45ef-524c-445c-b2d6-76216881c076"
   },
   "source": [
    "runner = InMemoryRunner(agent=migration_pipeline)\n",
    "\n",
    "await runner.run_debug(\"\"\"\n",
    "<p:commandButton\n",
    "    value=\"Save User\"\n",
    "    action=\"#{userBean.save}\"\n",
    "    update=\"userTable\"\n",
    "    icon=\"pi pi-save\"\n",
    "    styleClass=\"btn-blue\"\n",
    "    rendered=\"#{userBean.editMode}\"\n",
    "/>\n",
    "\"\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3FeFHkHBMGQL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "32cbfb62-e00c-417e-dfbd-bf910e005ca1"
   },
   "source": [
    "await runner.run_debug(\"\"\"\n",
    "<p:inputText\n",
    "    value=\"#{userBean.name}\"\n",
    "    required=\"true\"\n",
    "    maxlength=\"50\"\n",
    "    styleClass=\"input-big\"\n",
    "/>\n",
    "\"\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qznam-xriRq"
   },
   "source": [
    "# Second Modification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "S8UvBSGftAdj",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "40df97a3-9b9f-4b06-9d4f-f31f9ce117ac"
   },
   "source": [
    "!pip install -U google-generativeai google-genai google-adk"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "DnWt5ZF6rpTj",
    "outputId": "a4c410eb-8d59-422a-ae18-b4de5093e079"
   },
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "try:\n",
    "  api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "  os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "  print(\"API configured.\")\n",
    "except Exception as e:\n",
    "  print(f\"Missing API Key, Error: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "print(\"Project Root:\", PROJECT_ROOT)\n",
    "print(\"Using Model:\", MODEL_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_file_tool(path: str):\n",
    "    abs_path = os.path.join(PROJECT_ROOT, path)\n",
    "    if not os.path.exists(abs_path):\n",
    "        return {\"error\": f\"File not found: {path}\"}\n",
    "    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    return {\n",
    "        \"path\": path,\n",
    "        \"content\": content\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def write_file_tool(path: str, content: str):\n",
    "    abs_path = os.path.join(PROJECT_ROOT, path)\n",
    "    os.makedirs(os.path.dirname(abs_path), exist_ok=True)\n",
    "\n",
    "    with open(abs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    return{\n",
    "        \"status\": \"OK\",\n",
    "        \"path\": path\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jsf_logic_agent = Agent(\n",
    "    name=\"JSF_Logic_Agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Reads JSF/PrimeFaces .xhtml code and extracts all server-side logic, EL expressions, actions, methods, variables, bean references, and data dependencies.\",\n",
    "    instruction=\"\"\"\n",
    "    You specialize in JSF/PrimeFaces logic extraction.\n",
    "    Use the read_file_tool tool to load the .xhtml file.\n",
    "    Extract:\n",
    "    - All EL expressions (#{...})\n",
    "    - All bean methods (action, actionListener)\n",
    "    - All data table bindings (value, var)\n",
    "    - All inputs: value bindings, validation rules, converters\n",
    "    - Conditional rendering expressions\n",
    "    - Component ID dependencies\n",
    "    Output MUST be JSON with fields:\n",
    "    logic, actions, bindings, tables, forms, conditions\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"logic_report\"\n",
    ")\n",
    "print(\"JSF Logic Analyzer Agent Created\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jsf_visual_agent = Agent(\n",
    "    name=\"Jsf_Visual_Agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Extracts UI layout, structure, styling, dialogs, tables, forms, and widget hierarchy from JSF/PrimeFaces .xhtml.\",\n",
    "    instruction=\"\"\"\n",
    "    Use read_file_tool to load the .xhtml file.\n",
    "    Extract UI/Visual information:\n",
    "    - Layout containers (panelGrid, outputPanel, layout)\n",
    "    - Table columns, filters, sorting\n",
    "    - Dialogs, overlay panels\n",
    "    - Buttons and their placement\n",
    "    - CSS classes (styleClass)\n",
    "    - Inline styles\n",
    "    - Component hierarchy\n",
    "\n",
    "    Output MUST be JSON:\n",
    "    {\n",
    "      \"structure\": ...,\n",
    "      \"tables\": ...,\n",
    "      \"buttons\": ...,\n",
    "      \"dialogs\": ...,\n",
    "      \"styles\": ...\n",
    "    }\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"visual_report\"\n",
    ")\n",
    "print(\"JSF Visual Analyzer created.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "angular_architect_agent = Agent(\n",
    "    name=\"Angular_Architect_Agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Creates a unified Angular migration blueprint by combining JSF logic and visual structure.\",\n",
    "    instruction=\"\"\"\n",
    "    Use BOTH inputs:\n",
    "        Logic: {logic_report}\n",
    "        Visual: {visual_report}\n",
    "\n",
    "    Produce a full Angular migration blueprint:\n",
    "    - Angular components required\n",
    "    - Angular services for backend calls\n",
    "    - Reactive form definitions\n",
    "    - Angular Material equivalents for JSF widgets\n",
    "    - Table mapping (p:dataTable → MatTable)\n",
    "    - Dialog mapping (p:dialog → MatDialog)\n",
    "    - Routing structure\n",
    "    - Component interaction flow\n",
    "    - API endpoints (based on JSF actions)\n",
    "\n",
    "    Output MUST be JSON.\n",
    "    \"\"\",\n",
    "    output_key=\"migration_blueprint\"\n",
    ")\n",
    "print(\"Angular Architect Agent ready.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "angular_codegen_agent = Agent(\n",
    "    name=\"Angular_Code_Generator\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Writes Angular component/service files using the migration blueprint.\",\n",
    "    instruction=\"\"\"\n",
    "    Use this migration blueprint: {migration_blueprint}\n",
    "\n",
    "    Generate:\n",
    "      - Angular component.ts\n",
    "      - Angular component.html\n",
    "      - Angular component.css\n",
    "      - Angular service.ts\n",
    "\n",
    "    Use write_file_tool(path, contents) to save each file.\n",
    "\n",
    "    Paths:\n",
    "      output/component.ts\n",
    "      output/component.html\n",
    "      output/component.css\n",
    "      output/service.ts\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"generated_code\"\n",
    ")\n",
    "print(\"Angular Code Generator created.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "migration_pipeline = SequentialAgent(\n",
    "    name=\"JSF_to_Angular_Pipeline\",\n",
    "    sub_agents=[\n",
    "        jsf_logic_agent,\n",
    "        jsf_visual_agent,\n",
    "        angular_architect_agent,\n",
    "        angular_codegen_agent\n",
    "    ]\n",
    ")\n",
    "\n",
    "runner = InMemoryRunner(agent=migration_pipeline)\n",
    "\n",
    "print(\"Pipeline assembled.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = await runner.run_debug(\"input/sample.xhtml\")\n",
    "\n",
    "print(\"\\nFINAL PIPELINE OUTPUT:\\n\")\n",
    "print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Modification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import dotenv\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "INPUT_DIR = os.path.join(PROJECT_ROOT, \"input\")\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"output\")\n",
    "MEMORY_DIR = os.path.join(PROJECT_ROOT, \"memory\")\n",
    "MEMORY_PATH = os.path.join(MEMORY_DIR, \"project_memory.json\")\n",
    "\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MEMORY_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Project Root:\", PROJECT_ROOT)\n",
    "print(\"Model:\", MODEL_NAME)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_file_tool(path: str):\n",
    "    abs_path = os.path.join(PROJECT_ROOT, path)\n",
    "    if not os.path.exists(abs_path):\n",
    "        return {\"error\": f\"File not found: {path}\"}\n",
    "    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return {\"path\": path, \"content\": f.read()}\n",
    "\n",
    "def write_file_tool(path: str, content: str):\n",
    "    abs_path = os.path.join(PROJECT_ROOT, path)\n",
    "    os.makedirs(os.path.dirname(abs_path), exist_ok=True)\n",
    "    with open(abs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return {\"status\": \"OK\", \"path\": path}\n",
    "\n",
    "def load_persistent_memory():\n",
    "    if os.path.exists(MEMORY_PATH):\n",
    "        with open(MEMORY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "project_scanner_agent = Agent(\n",
    "    name=\"Project_Scanner\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Scans all .xhtml pages to build global project memory.\",\n",
    "    instruction=r\"\"\"\n",
    "    You will scan multiple JSF .xhtml pages.\n",
    "\n",
    "    IMPORTANT:\n",
    "    In this instruction, JSF expressions are written using ${...} to avoid template substitution.\n",
    "    But in the REAL files you load via read_file_tool, the syntax will be #{...}.\n",
    "    Treat BOTH the same way.\n",
    "\n",
    "    INPUT:\n",
    "    A JSON array of file paths.\n",
    "\n",
    "    TASKS:\n",
    "    - Use read_file_tool to load each file\n",
    "    - Extract:\n",
    "        • bean references (look for \"#{...}\" in the file)\n",
    "        • dataTables\n",
    "        • dialogs\n",
    "        • forms\n",
    "        • repeated components\n",
    "        • CSS classes\n",
    "        • title/header/navigation patterns\n",
    "\n",
    "    OUTPUT JSON:\n",
    "    {\n",
    "      \"global_beans\": [...],\n",
    "      \"global_tables\": [...],\n",
    "      \"global_dialogs\": [...],\n",
    "      \"common_components\": [...],\n",
    "      \"styles\": [...]\n",
    "    }\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"project_memory\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "memory_persistor_agent = Agent(\n",
    "    name=\"Memory_Persistor\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Writes project-wide memory to disk.\",\n",
    "    instruction=r\"\"\"\n",
    "    Take project memory from [[project_memory]].\n",
    "    Convert it to JSON.\n",
    "    Save to: memory/project_memory.json using write_file_tool.\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"memory_saved\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jsf_logic_agent = Agent(\n",
    "    name=\"JSF_Logic_Extractor\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    You extract JSF logic from an .xhtml file.\n",
    "\n",
    "    IMPORTANT:\n",
    "    In this instruction, JSF EL uses ${...}.\n",
    "    In the REAL file you read, it will be #{...}.\n",
    "    Treat both ${...} and #{...} as EL expressions.\n",
    "\n",
    "    INPUT JSON:\n",
    "    {\n",
    "        \"file_path\": \"...\",\n",
    "        \"project_memory\": <memory object>\n",
    "    }\n",
    "\n",
    "    Extract:\n",
    "    - EL expressions (#{...})\n",
    "    - bean method calls (action=, actionListener=)\n",
    "    - data table bindings\n",
    "    - form bindings\n",
    "    - validation rules\n",
    "    - update/process (AJAX rules)\n",
    "    - conditional rendering\n",
    "\n",
    "    OUTPUT JSON:\n",
    "    { \"logic_report\": ... }\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"logic_report\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jsf_visual_agent = Agent(\n",
    "    name=\"JSF_Visual_Extractor\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    You extract UI structure from a JSF file.\n",
    "\n",
    "    IMPORTANT RULES:\n",
    "    - The ONLY tool you are allowed to call is read_file_tool.\n",
    "    - DO NOT call any other tool.\n",
    "    - DO NOT invent functions such as 'extract_ui_structure', 'parse_dom', etc.\n",
    "    - You must simply read the file and analyze its text.\n",
    "\n",
    "    INPUT JSON:\n",
    "    {\n",
    "        \"file_path\": \"...\",\n",
    "        \"project_memory\": [[project_memory]]\n",
    "    }\n",
    "\n",
    "    Extract (BY READING THE TEXT YOURSELF):\n",
    "    - layout blocks (panelGrid, div, panelGroup)\n",
    "    - dialogs\n",
    "    - dataTables\n",
    "    - buttons\n",
    "    - CSS classes\n",
    "    - inline styles\n",
    "    - structure hierarchy\n",
    "\n",
    "    Then output JSON:\n",
    "    {\n",
    "      \"visual_report\": { ... }\n",
    "    }\n",
    "\n",
    "    AGAIN: Use ONLY read_file_tool. DO NOT call any invented tools.\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"visual_report\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "angular_architect_agent = Agent(\n",
    "    name=\"Angular_Architect\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    You combine:\n",
    "      - project memory: [[project_memory]]\n",
    "      - logic: [[logic_report]]\n",
    "      - visuals: [[visual_report]]\n",
    "\n",
    "    Produce an Angular migration blueprint:\n",
    "      - component name\n",
    "      - Angular Material equivalents\n",
    "      - services needed\n",
    "      - routing path\n",
    "      - shared components\n",
    "      - form structure\n",
    "      - table/dialog mappings\n",
    "\n",
    "    OUTPUT MUST BE JSON.\n",
    "    \"\"\",\n",
    "    output_key=\"migration_blueprint\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "angular_codegen_agent = Agent(\n",
    "    name=\"Angular_Code_Generator\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    Input: [[migration_blueprint]]\n",
    "\n",
    "    Generate:\n",
    "      - component.ts\n",
    "      - component.html\n",
    "      - component.css\n",
    "      - service.ts\n",
    "\n",
    "    Use write_file_tool to save them under output/<component-name>/.\n",
    "\n",
    "    Output JSON list of created files.\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"generated_files\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bootstrap_pipeline = SequentialAgent(\n",
    "    name=\"Bootstrap\",\n",
    "    sub_agents=[\n",
    "        project_scanner_agent,\n",
    "        memory_persistor_agent\n",
    "    ]\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "migration_pipeline = SequentialAgent(\n",
    "    name=\"Migration\",\n",
    "    sub_agents=[\n",
    "        jsf_logic_agent,\n",
    "        jsf_visual_agent,\n",
    "        angular_architect_agent,\n",
    "        angular_codegen_agent\n",
    "    ]\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bootstrap_runner = InMemoryRunner(agent=bootstrap_pipeline)\n",
    "migration_runner = InMemoryRunner(agent=migration_pipeline)\n",
    "\n",
    "async def run_all():\n",
    "    files = glob.glob(\"input/*.xhtml\")\n",
    "    if not files:\n",
    "        print(\"No XHTML files found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nBUILDING PROJECT MEMORY…\")\n",
    "    await bootstrap_runner.run_debug(json.dumps(files))\n",
    "\n",
    "    project_memory = load_persistent_memory()\n",
    "    print(\"\\nLoaded Project Memory\")\n",
    "\n",
    "    print(\"\\nMIGRATING PAGES…\")\n",
    "    for f in files:\n",
    "        await migration_runner.run_debug(json.dumps({\n",
    "            \"file_path\": f,\n",
    "            \"project_memory\": project_memory\n",
    "        }))\n",
    "        print(\"  -> Waiting 5 seconds to respect API quota...\")\n",
    "        await asyncio.sleep(20)\n",
    "await run_all()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forth Modification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import dotenv\n",
    "import asyncio\n",
    "import time\n",
    "from typing import List, Any\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if api_key:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "INPUT_DIR = os.path.join(PROJECT_ROOT, \"input\")\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"output\")\n",
    "MEMORY_DIR = os.path.join(PROJECT_ROOT, \"memory\")\n",
    "MEMORY_PATH = os.path.join(MEMORY_DIR, \"project_memory.json\")\n",
    "OBS_DIR = os.path.join(PROJECT_ROOT, \"observability\")\n",
    "\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MEMORY_DIR, exist_ok=True)\n",
    "os.makedirs(OBS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Project Root:\", PROJECT_ROOT)\n",
    "print(\"Model:\", MODEL_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_file_tool(path: str):\n",
    "    abs_path = os.path.join(PROJECT_ROOT, path)\n",
    "    if not os.path.exists(abs_path):\n",
    "        return {\"error\": f\"File not found: {path}\"}\n",
    "    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return {\"path\": path, \"content\": f.read()}\n",
    "\n",
    "def write_file_tool(path: str, content: str):\n",
    "    abs_path = os.path.join(PROJECT_ROOT, path)\n",
    "    os.makedirs(os.path.dirname(abs_path), exist_ok=True)\n",
    "    with open(abs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return {\"status\": \"OK\", \"path\": path}\n",
    "\n",
    "def load_persistent_memory():\n",
    "    if os.path.exists(MEMORY_PATH):\n",
    "        with open(MEMORY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "async def observe_run(runner: InMemoryRunner, payload: Any, run_label: str):\n",
    "    \"\"\"Runs an agent with logging (Observability).\"\"\"\n",
    "    start = time.time()\n",
    "    # Ensure payload is a string for run_debug\n",
    "    payload_str = json.dumps(payload) if not isinstance(payload, str) else payload\n",
    "    \n",
    "    print(f\"\\n[OBSERVABILITY] Starting {run_label}...\")\n",
    "    try:\n",
    "        result = await runner.run_debug(payload_str)\n",
    "    except Exception as e:\n",
    "        result = f\"ERROR: {str(e)}\"\n",
    "        print(f\"[OBSERVABILITY] Error in {run_label}: {e}\")\n",
    "    \n",
    "    duration = time.time() - start\n",
    "    \n",
    "    log_entry = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"label\": run_label,\n",
    "        \"duration_sec\": duration,\n",
    "        \"payload_summary\": str(payload)[:500],\n",
    "        \"result_summary\": str(result)[:500]\n",
    "    }\n",
    "    \n",
    "    log_path = os.path.join(OBS_DIR, \"logs.jsonl\")\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(log_entry) + \"\\n\")\n",
    "    \n",
    "    print(f\"[OBSERVABILITY] Finished {run_label} in {duration:.2f}s\")\n",
    "    return result\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "project_scanner_agent = Agent(\n",
    "    name=\"Project_Scanner\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Scans all .xhtml pages to build global project memory.\",\n",
    "    instruction=r\"\"\"\n",
    "    You will scan multiple JSF .xhtml pages.\n",
    "\n",
    "    IMPORTANT:\n",
    "    In this instruction, JSF expressions are written using ${...} to avoid template substitution.\n",
    "    But in the REAL files you load via read_file_tool, the syntax will be #{...}.\n",
    "    Treat BOTH the same way.\n",
    "\n",
    "    INPUT:\n",
    "    A JSON array of file paths.\n",
    "\n",
    "    TASKS:\n",
    "    - Use read_file_tool to load each file\n",
    "    - Extract:\n",
    "        • bean references (look for \"#{...}\" in the file)\n",
    "        • dataTables\n",
    "        • dialogs\n",
    "        • forms\n",
    "        • repeated components\n",
    "        • CSS classes\n",
    "        • title/header/navigation patterns\n",
    "\n",
    "    OUTPUT JSON:\n",
    "    {\n",
    "      \"global_beans\": [...],\n",
    "      \"global_tables\": [...],\n",
    "      \"global_dialogs\": [...],\n",
    "      \"common_components\": [...],\n",
    "      \"styles\": [...]\n",
    "    }\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"project_memory\"\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "memory_persistor_agent = Agent(\n",
    "    name=\"Memory_Persistor\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Writes project-wide memory to disk.\",\n",
    "    instruction=r\"\"\"\n",
    "    Take project memory from [[project_memory]].\n",
    "    Convert it to JSON.\n",
    "    Save to: memory/project_memory.json using write_file_tool.\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"memory_saved\"\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jsf_logic_agent = Agent(\n",
    "    name=\"JSF_Logic_Extractor\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    You extract JSF logic from an .xhtml file.\n",
    "\n",
    "    IMPORTANT:\n",
    "    In this instruction, JSF EL uses ${...}.\n",
    "    In the REAL file you read, it will be #{...}.\n",
    "    Treat both ${...} and #{...} as EL expressions.\n",
    "\n",
    "    INPUT JSON:\n",
    "    {\n",
    "        \"file_path\": \"...\",\n",
    "        \"project_memory\": <memory object>\n",
    "    }\n",
    "\n",
    "    Extract:\n",
    "    - EL expressions (#{...})\n",
    "    - bean method calls (action=, actionListener=)\n",
    "    - data table bindings\n",
    "    - form bindings\n",
    "    - validation rules\n",
    "    - update/process (AJAX rules)\n",
    "    - conditional rendering\n",
    "\n",
    "    OUTPUT JSON:\n",
    "    { \"logic_report\": ... }\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"logic_report\"\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jsf_visual_agent = Agent(\n",
    "    name=\"JSF_Visual_Extractor\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    You extract UI structure from a JSF file.\n",
    "\n",
    "    IMPORTANT RULES:\n",
    "    - The ONLY tool you are allowed to call is read_file_tool.\n",
    "    - DO NOT call any other tool.\n",
    "    - DO NOT invent functions such as 'extract_ui_structure', 'parse_dom', etc.\n",
    "    - You must simply read the file and analyze its text.\n",
    "\n",
    "    INPUT JSON:\n",
    "    {\n",
    "        \"file_path\": \"...\",\n",
    "        \"project_memory\": [[project_memory]]\n",
    "    }\n",
    "\n",
    "    Extract (BY READING THE TEXT YOURSELF):\n",
    "    - layout blocks (panelGrid, div, panelGroup)\n",
    "    - dialogs\n",
    "    - dataTables\n",
    "    - buttons\n",
    "    - CSS classes\n",
    "    - inline styles\n",
    "    - structure hierarchy\n",
    "\n",
    "    Then output JSON:\n",
    "    {\n",
    "      \"visual_report\": { ... }\n",
    "    }\n",
    "\n",
    "    AGAIN: Use ONLY read_file_tool. DO NOT call any invented tools.\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"visual_report\"\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Updated Angular Architect with Google Search (Mod 4)\n",
    "angular_architect_agent = Agent(\n",
    "    name=\"Angular_Architect\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    You combine:\n",
    "      - project memory: [[project_memory]]\n",
    "      - logic: [[logic_report]]\n",
    "      - visuals: [[visual_report]]\n",
    "\n",
    "    Produce an Angular migration blueprint:\n",
    "      - component name\n",
    "      - Angular Material equivalents\n",
    "      - services needed\n",
    "      - routing path\n",
    "      - shared components\n",
    "      - form structure\n",
    "      - table/dialog mappings\n",
    "\n",
    "    IMPORTANT:\n",
    "    - If you encounter a JSF component and are unsure of its Angular equivalent, use the 'google_search' tool to find the best match.\n",
    "    - Example query: \"PrimeFaces p:dataTable Angular Material equivalent\"\n",
    "\n",
    "    OUTPUT MUST BE JSON.\n",
    "    \"\"\",\n",
    "    tools=[google_search], # Added google_search\n",
    "    output_key=\"migration_blueprint\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "angular_codegen_agent = Agent(\n",
    "    name=\"Angular_Code_Generator\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    Input: [[migration_blueprint]]\n",
    "\n",
    "    Generate:\n",
    "      - component.ts\n",
    "      - component.html\n",
    "      - component.css\n",
    "      - service.ts\n",
    "\n",
    "    Use write_file_tool to save them under output/<component-name>/.\n",
    "\n",
    "    Output JSON list of created files.\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"generated_files\"\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Added Evaluation Agent (Day 4b)\n",
    "evaluation_agent = Agent(\n",
    "    name=\"Migration_Evaluator\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    INPUTS: [[migration_blueprint]], [[generated_files]], [[project_memory]]\n",
    "\n",
    "    TASK: Evaluate the quality of the migration.\n",
    "    - Check Structural Completeness (Are all components present?)\n",
    "    - Check Mapping Accuracy (Do bindings match?)\n",
    "    - Check Style/Best Practices.\n",
    "\n",
    "    OUTPUT JSON:\n",
    "    {\n",
    "      \"evaluation_report\": {\n",
    "        \"score\": 0.0-10.0,\n",
    "        \"issues\": [...],\n",
    "        \"recommendations\": [...]\n",
    "      }\n",
    "    }\n",
    "    \"\"\",\n",
    "    output_key=\"evaluation_report\"\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bootstrap_pipeline = SequentialAgent(\n",
    "    name=\"Bootstrap\",\n",
    "    sub_agents=[\n",
    "        project_scanner_agent,\n",
    "        memory_persistor_agent\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "migration_pipeline = SequentialAgent(\n",
    "    name=\"Migration\",\n",
    "    sub_agents=[\n",
    "        jsf_logic_agent,\n",
    "        jsf_visual_agent,\n",
    "        angular_architect_agent,\n",
    "        angular_codegen_agent,\n",
    "        evaluation_agent  # Added Evaluator\n",
    "    ]\n",
    ")\n",
    "\n",
    "bootstrap_runner = InMemoryRunner(agent=bootstrap_pipeline)\n",
    "migration_runner = InMemoryRunner(agent=migration_pipeline)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "async def run_all():\n",
    "    files = glob.glob(os.path.join(INPUT_DIR, \"*.xhtml\"))\n",
    "    if not files:\n",
    "        print(\"⚠ No XHTML files found.\")\n",
    "        return\n",
    "\n",
    "    rel_files = [os.path.relpath(f, PROJECT_ROOT) for f in files]\n",
    "\n",
    "    print(\"\\nBUILDING PROJECT MEMORY…\")\n",
    "    # Use observe_run for Bootstrap\n",
    "    await observe_run(bootstrap_runner, rel_files, \"Bootstrap\")\n",
    "\n",
    "    project_memory = load_persistent_memory()\n",
    "    print(\"\\nLoaded Project Memory\")\n",
    "\n",
    "    print(\"\\nMIGRATING PAGES…\")\n",
    "    for f in files:\n",
    "        rel = os.path.relpath(f, PROJECT_ROOT)\n",
    "        print(f\"\\n--- Migrating {rel} ---\")\n",
    "\n",
    "        payload = {\n",
    "            \"file_path\": rel,\n",
    "            \"project_memory\": project_memory\n",
    "        }\n",
    "\n",
    "        # Use observe_run for Migration\n",
    "        await observe_run(migration_runner, payload, f\"Migration:{rel}\")\n",
    "\n",
    "        print(\"  -> Waiting 5 seconds to respect API quota...\")\n",
    "        await asyncio.sleep(5)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run_all())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fifth Modification"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.867695Z",
     "start_time": "2025-11-28T18:28:01.824226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import dotenv\n",
    "import asyncio\n",
    "import time\n",
    "import shutil\n",
    "import traceback\n",
    "from typing import Any, Dict, List, Optional\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gemini-2.5-flash-lite\")\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "INPUT_DIR = os.path.join(PROJECT_ROOT, \"input\")\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"output\")\n",
    "MEMORY_DIR = os.path.join(PROJECT_ROOT, \"memory\")\n",
    "OBS_DIR = os.path.join(PROJECT_ROOT, \"observability\")\n",
    "LOG_PATH = os.path.join(OBS_DIR, \"logs.jsonl\")\n",
    "METRICS_PATH = os.path.join(OBS_DIR, \"metrics.json\")\n",
    "PROJECT_MEMORY_PATH = os.path.join(MEMORY_DIR, \"project_memory.json\")\n",
    "\n",
    "MAX_CONCURRENT_MIGRATIONS = int(os.getenv(\"MAX_CONCURRENT_MIGRATIONS\", \"2\"))\n",
    "MAX_RETRIES = int(os.getenv(\"MAX_RETRIES\", \"4\"))\n",
    "BASE_RETRY_DELAY = float(os.getenv(\"BASE_RETRY_DELAY\", \"5.0\"))\n",
    "\n",
    "QUOTA_BACKOFF_INITIAL = float(os.getenv(\"QUOTA_BACKOFF_INITIAL\", \"30.0\"))\n",
    "\n",
    "# Create directories if missing\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MEMORY_DIR, exist_ok=True)\n",
    "os.makedirs(OBS_DIR, exist_ok=True)\n",
    "\n",
    "# Set Google env var\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if api_key:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = os.getenv(\"GOOGLE_GENAI_USE_VERTEXAI\", \"FALSE\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.877869Z",
     "start_time": "2025-11-28T18:28:05.873125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def now_ts() -> float:\n",
    "    return time.time()\n",
    "\n",
    "def write_log(entry: Dict[str, Any]) -> None:\n",
    "    \"\"\"Append JSON log line to logs.jsonl\"\"\"\n",
    "    entry = dict(entry)\n",
    "    entry.setdefault(\"ts\", datetime.now(timezone.utc).isoformat())\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, default=str) + \"\\n\")\n",
    "\n",
    "def load_metrics() -> Dict[str, Any]:\n",
    "    if os.path.exists(METRICS_PATH):\n",
    "        try:\n",
    "            with open(METRICS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def update_metric(k: str, v: Any) -> None:\n",
    "    m = load_metrics()\n",
    "    m[k] = v\n",
    "    with open(METRICS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(m, f, indent=2)\n",
    "\n",
    "class MemoryBank:\n",
    "    \"\"\"\n",
    "    Simple ephemeral memory bank used by agents during a run.\n",
    "    Persisted to disk only for debugging; removed at end of run per requirement.\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str = PROJECT_MEMORY_PATH):\n",
    "        self.path = path\n",
    "        self._store: Dict[str, Any] = {}\n",
    "\n",
    "    def load(self) -> None:\n",
    "        if os.path.exists(self.path):\n",
    "            try:\n",
    "                with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    self._store = json.load(f)\n",
    "            except Exception:\n",
    "                self._store = {}\n",
    "        else:\n",
    "            self._store = {}\n",
    "\n",
    "    def save(self) -> None:\n",
    "        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n",
    "        with open(self.path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self._store, f, indent=2)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self._store = {}\n",
    "        try:\n",
    "            if os.path.exists(self.path):\n",
    "                os.remove(self.path)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def get(self, key: str, default=None):\n",
    "        return self._store.get(key, default)\n",
    "\n",
    "    def set(self, key: str, value: Any) -> None:\n",
    "        self._store[key] = value\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.885154Z",
     "start_time": "2025-11-28T18:28:05.881625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MEMORY = MemoryBank(PROJECT_MEMORY_PATH)\n",
    "\n",
    "class SessionManager:\n",
    "    \"\"\"\n",
    "    Manage per-run sessions and allow pause/resume/cancel for long-running ops.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # session_id -> dict(status,event,cancel)\n",
    "        self.sessions: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def create_session(self, session_id: str):\n",
    "        if session_id in self.sessions:\n",
    "            return self.sessions[session_id]\n",
    "        ev = asyncio.Event()\n",
    "        ev.set()  # default: not paused\n",
    "        self.sessions[session_id] = {\"paused\": False, \"pause_event\": ev, \"cancel\": False}\n",
    "        return self.sessions[session_id]\n",
    "\n",
    "    def pause(self, session_id: str):\n",
    "        s = self.sessions.get(session_id)\n",
    "        if s:\n",
    "            s[\"paused\"] = True\n",
    "            s[\"pause_event\"].clear()\n",
    "\n",
    "    def resume(self, session_id: str):\n",
    "        s = self.sessions.get(session_id)\n",
    "        if s:\n",
    "            s[\"paused\"] = False\n",
    "            s[\"pause_event\"].set()\n",
    "\n",
    "    def cancel(self, session_id: str):\n",
    "        s = self.sessions.get(session_id)\n",
    "        if s:\n",
    "            s[\"cancel\"] = True\n",
    "            s[\"pause_event\"].set()\n",
    "\n",
    "    def is_cancelled(self, session_id: str) -> bool:\n",
    "        s = self.sessions.get(session_id)\n",
    "        return bool(s and s.get(\"cancel\"))\n",
    "\n",
    "    def get_event(self, session_id: str) -> Optional[asyncio.Event]:\n",
    "        s = self.sessions.get(session_id)\n",
    "        return s.get(\"pause_event\") if s else None\n",
    "\n",
    "SESSION_MANAGER = SessionManager()\n",
    "\n",
    "class A2AMessenger:\n",
    "    def __init__(self):\n",
    "        self.queues: Dict[str, asyncio.Queue] = {}\n",
    "\n",
    "    def get_queue(self, name: str) -> asyncio.Queue:\n",
    "        if name not in self.queues:\n",
    "            self.queues[name] = asyncio.Queue()\n",
    "        return self.queues[name]\n",
    "\n",
    "    async def send(self, name: str, msg: Any):\n",
    "        await self.get_queue(name).put(msg)\n",
    "\n",
    "    async def recv(self, name: str, timeout: Optional[float] = None) -> Any:\n",
    "        q = self.get_queue(name)\n",
    "        if timeout:\n",
    "            try:\n",
    "                return await asyncio.wait_for(q.get(), timeout=timeout)\n",
    "            except asyncio.TimeoutError:\n",
    "                return None\n",
    "        return await q.get()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.892129Z",
     "start_time": "2025-11-28T18:28:05.888676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A2A = A2AMessenger()\n",
    "\n",
    "def read_file_tool(path: str):\n",
    "    # Accept either absolute path or relative path under input root\n",
    "    abs_path = path if os.path.isabs(path) else os.path.join(INPUT_DIR, path)\n",
    "    if not os.path.exists(abs_path):\n",
    "        return {\"error\": f\"File not found: {abs_path}\"}\n",
    "    try:\n",
    "        with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        return {\"path\": path, \"content\": content}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Read error: {e}\"}\n",
    "\n",
    "def write_file_tool(path: str, content: str):\n",
    "    # Save under OUTPUT_DIR unless absolute\n",
    "    abs_path = path if os.path.isabs(path) else os.path.join(OUTPUT_DIR, path)\n",
    "    os.makedirs(os.path.dirname(abs_path), exist_ok=True)\n",
    "    with open(abs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return {\"status\": \"OK\", \"path\": abs_path}\n",
    "\n",
    "def compact_context(obj: Any, max_chars: int = 2000) -> Any:\n",
    "    \"\"\"\n",
    "    Trims large string fields in nested dict/list structures to keep messages small.\n",
    "    This is a conservative compaction for agent payloads.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, str):\n",
    "        return obj if len(obj) <= max_chars else obj[:max_chars] + \"...[truncated]\"\n",
    "    if isinstance(obj, dict):\n",
    "        out = {}\n",
    "        for k, v in obj.items():\n",
    "            # keep key names, compact values\n",
    "            out[k] = compact_context(v, max_chars=max_chars // 4 if k.lower().endswith(\"content\") else max_chars)\n",
    "        return out\n",
    "    if isinstance(obj, list):\n",
    "        # If list too long, take first N items\n",
    "        if len(obj) > 50:\n",
    "            obj = obj[:50] + [\"...[truncated items]\"]\n",
    "        return [compact_context(x, max_chars=max_chars) for x in obj]\n",
    "    return obj\n",
    "\n",
    "async def observe_run(runner: InMemoryRunner, payload: Any, run_label: str, session_id: Optional[str] = None, semaphore: Optional[asyncio.Semaphore] = None):\n",
    "    \"\"\"\n",
    "    Runs runner.run_debug with:\n",
    "     - context compaction\n",
    "     - retries with backoff for RESOURCE_EXHAUSTED or transient errors\n",
    "     - session pause/resume/cancel cooperation\n",
    "     - concurrency semaphore (if provided)\n",
    "    Returns the runner result (or error string)\n",
    "    \"\"\"\n",
    "    compacted = compact_context(payload, max_chars=4000)\n",
    "    payload_str = json.dumps(compacted) if not isinstance(compacted, str) else compacted\n",
    "\n",
    "    attempt = 0\n",
    "    last_exc = None\n",
    "    start_all = now_ts()\n",
    "    session = session_id or f\"session_default\"\n",
    "\n",
    "    if semaphore:\n",
    "        await semaphore.acquire()\n",
    "\n",
    "    try:\n",
    "        # Ensure session exists\n",
    "        SESSION_MANAGER.create_session(session)\n",
    "\n",
    "        while attempt < MAX_RETRIES:\n",
    "            attempt += 1\n",
    "            # respect pause\n",
    "            ev = SESSION_MANAGER.get_event(session)\n",
    "            if ev:\n",
    "                await ev.wait()\n",
    "            # check for cancellation\n",
    "            if SESSION_MANAGER.is_cancelled(session):\n",
    "                write_log({\"label\": run_label, \"event\": \"cancelled\", \"attempt\": attempt})\n",
    "                return {\"error\": \"CANCELLED\"}\n",
    "\n",
    "            start = now_ts()\n",
    "            try:\n",
    "                write_log({\"label\": run_label, \"event\": \"start_attempt\", \"attempt\": attempt})\n",
    "                result = await runner.run_debug(payload_str)\n",
    "                duration = now_ts() - start\n",
    "                write_log({\"label\": run_label, \"event\": \"success\", \"attempt\": attempt, \"duration\": duration})\n",
    "                # update metrics\n",
    "                m = load_metrics()\n",
    "                m.setdefault(\"successful_runs\", 0)\n",
    "                m[\"successful_runs\"] += 1\n",
    "                update_metric(\"successful_runs\", m[\"successful_runs\"])\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                last_exc = e\n",
    "                msg = str(e)\n",
    "                duration = now_ts() - start\n",
    "                write_log({\"label\": run_label, \"event\": \"error\", \"attempt\": attempt, \"duration\": duration, \"error\": msg})\n",
    "                # inspect message for quota-like issues\n",
    "                low = msg.lower()\n",
    "                if \"resource_exhausted\" in low or \"quota\" in low or \"429\" in low or \"rate-limit\" in low:\n",
    "                    # backoff then retry\n",
    "                    wait = QUOTA_BACKOFF_INITIAL * (1.5 ** (attempt - 1))\n",
    "                    write_log({\"label\": run_label, \"event\": \"quota_backoff\", \"attempt\": attempt, \"wait_seconds\": wait})\n",
    "                    await asyncio.sleep(wait)\n",
    "                    continue\n",
    "                # transient pattern\n",
    "                if \"unavailable\" in low or \"timeout\" in low or \"internal\" in low:\n",
    "                    wait = BASE_RETRY_DELAY * (2 ** (attempt - 1))\n",
    "                    await asyncio.sleep(wait)\n",
    "                    continue\n",
    "                # non-transient: break and return\n",
    "                write_log({\"label\": run_label, \"event\": \"non_retriable\", \"message\": msg})\n",
    "                return {\"error\": msg}\n",
    "        # exhausted\n",
    "        write_log({\"label\": run_label, \"event\": \"max_retries_exceeded\", \"last_error\": str(last_exc)})\n",
    "        return {\"error\": f\"Max retries exceeded: {last_exc}\"}\n",
    "    finally:\n",
    "        if semaphore:\n",
    "            semaphore.release()\n",
    "        total_dur = now_ts() - start_all\n",
    "        write_log({\"label\": run_label, \"event\": \"finished_observe_run\", \"total_duration\": total_dur, \"attempts\": attempt})\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.903219Z",
     "start_time": "2025-11-28T18:28:05.896273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_scanner_agent = Agent(\n",
    "    name=\"Project_Scanner\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Scans all .xhtml pages to build global project memory.\",\n",
    "    instruction=r\"\"\"\n",
    "    INPUT: JSON array of file paths (relative to input/).\n",
    "    TASKS:\n",
    "      - Use read_file_tool(path) to load each file's content.\n",
    "      - Extract bean references (#{...}), dataTables, dialogs, forms, repeated components, CSS classes, titles.\n",
    "      - Output JSON: { \"global_beans\": [...], \"global_tables\": [...], \"global_dialogs\": [...], \"common_components\": [...], \"styles\": [...] }\n",
    "    IMPORTANT: CALL only read_file_tool when accessing files.\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"project_memory\"\n",
    ")\n",
    "\n",
    "memory_persistor_agent = Agent(\n",
    "    name=\"Memory_Persistor\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Persists project memory to disk during run (deleted after run).\",\n",
    "    instruction=r\"\"\"\n",
    "    INPUT: [[project_memory]]\n",
    "    TASK:\n",
    "      - Use write_file_tool to save memory/project_memory.json with the provided project_memory content.\n",
    "      - Output { \"status\":\"saved\", \"path\":\"memory/project_memory.json\" }\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"memory_saved\"\n",
    ")\n",
    "\n",
    "jsf_logic_agent = Agent(\n",
    "    name=\"JSF_Logic_Extractor\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    INPUT: { \"file_path\": \"...\", \"project_memory\": {...} }\n",
    "    TASK:\n",
    "      - Call read_file_tool(file_path)\n",
    "      - Extract EL expressions (#{...}), bean method calls (action=, actionListener=), data tables, form bindings, validations, ajax update/process attributes.\n",
    "      - Output JSON: { \"logic_report\": {...} }\n",
    "    IMPORTANT: Treat both #{...} and ${...} as EL.\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"logic_report\"\n",
    ")\n",
    "\n",
    "jsf_visual_agent = Agent(\n",
    "    name=\"JSF_Visual_Extractor\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    INPUT: { \"file_path\": \"...\", \"project_memory\": {...} }\n",
    "    TASK:\n",
    "      - Call read_file_tool(file_path) ONLY.\n",
    "      - Extract UI structure: layout blocks, dialogs, dataTables, buttons, CSS classes, inline styles, structure hierarchy.\n",
    "      - Output JSON: { \"visual_report\": {...} }\n",
    "    IMPORTANT: Do not invent or call other tools.\n",
    "    \"\"\",\n",
    "    tools=[read_file_tool],\n",
    "    output_key=\"visual_report\"\n",
    ")\n",
    "\n",
    "angular_architect_agent = Agent(\n",
    "    name=\"Angular_Architect\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    INPUT: [[project_memory]], [[logic_report]], [[visual_report]]\n",
    "    TASK:\n",
    "      - Produce a migration_blueprint (JSON) with:\n",
    "        - component_name (kebab-case),\n",
    "        - angular_equivalents mapping,\n",
    "        - services_needed,\n",
    "        - routing_path,\n",
    "        - form_structure,\n",
    "        - table/dialog mappings\n",
    "      - If unsure about a PrimeFaces->Angular mapping, use google_search(...) tool.\n",
    "    OUTPUT: { \"migration_blueprint\": {...} }\n",
    "    \"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"migration_blueprint\"\n",
    ")\n",
    "\n",
    "angular_codegen_agent = Agent(\n",
    "    name=\"Angular_Code_Generator\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    INPUT: [[migration_blueprint]]\n",
    "    TASK:\n",
    "      - Generate component TS/HTML/CSS and stub services under <component-name>/ using write_file_tool.\n",
    "      - Follow these rules:\n",
    "         - Dashboard component must subscribe to DashboardService.getUserStats()\n",
    "         - Users component must use MatTableDataSource; editUser should copy object with {...u}\n",
    "         - Service calls should use catchError and return of([]) for list endpoints\n",
    "    OUTPUT: { \"generated_files\": [ ... ] }\n",
    "    \"\"\",\n",
    "    tools=[write_file_tool],\n",
    "    output_key=\"generated_files\"\n",
    ")\n",
    "\n",
    "evaluation_agent = Agent(\n",
    "    name=\"Migration_Evaluator\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=r\"\"\"\n",
    "    INPUTS: [[migration_blueprint]], [[generated_files]], [[project_memory]]\n",
    "    TASK:\n",
    "      - Produce evaluation_report with score (0..10), issues[], recommendations[]\n",
    "    OUTPUT: { \"evaluation_report\": {...} }\n",
    "    \"\"\",\n",
    "    output_key=\"evaluation_report\"\n",
    ")\n",
    "\n",
    "# Pipelines\n",
    "bootstrap_pipeline = SequentialAgent(name=\"Bootstrap_Pipeline\", sub_agents=[project_scanner_agent, memory_persistor_agent])\n",
    "migration_pipeline = SequentialAgent(name=\"Migration_Pipeline\", sub_agents=[jsf_logic_agent, jsf_visual_agent, angular_architect_agent, angular_codegen_agent, evaluation_agent])\n",
    "\n",
    "# Runners\n",
    "bootstrap_runner = InMemoryRunner(agent=bootstrap_pipeline)\n",
    "migration_runner = InMemoryRunner(agent=migration_pipeline)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.911589Z",
     "start_time": "2025-11-28T18:28:05.906887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def run_mod5(session_id: str = \"session_default\"):\n",
    "    \"\"\"\n",
    "    Top-level orchestrator.\n",
    "    - Clears memory dir at start and end.\n",
    "    - Uses bounded concurrency for migrations.\n",
    "    \"\"\"\n",
    "    start_time = now_ts()\n",
    "    write_log({\"event\": \"run_start\", \"session\": session_id, \"model\": MODEL_NAME})\n",
    "    if os.path.exists(MEMORY_DIR):\n",
    "        try:\n",
    "            shutil.rmtree(MEMORY_DIR)\n",
    "        except Exception:\n",
    "            pass\n",
    "    os.makedirs(MEMORY_DIR, exist_ok=True)\n",
    "    MEMORY.clear()\n",
    "    MEMORY.load()\n",
    "\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_MIGRATIONS)\n",
    "\n",
    "    try:\n",
    "        # Bootstrap (project memory)\n",
    "        xhtml_files = sorted(glob.glob(os.path.join(INPUT_DIR, \"*.xhtml\")))\n",
    "        rel_files = [os.path.relpath(f, INPUT_DIR) for f in xhtml_files]\n",
    "        write_log({\"event\": \"bootstrap_start\", \"file_count\": len(rel_files)})\n",
    "        boot_res = await observe_run(bootstrap_runner, rel_files, \"Bootstrap\", session_id, semaphore=None)\n",
    "        # if bootstrap produced memory file, load to MEMORY\n",
    "        MEMORY.load()\n",
    "        write_log({\"event\": \"bootstrap_result\", \"result_summary\": str(boot_res)[:500]})\n",
    "        # Migrate pages (bounded concurrency with tasks)\n",
    "        write_log({\"event\": \"migrate_start\", \"pages\": rel_files})\n",
    "        # tracking results\n",
    "        migration_results = {}\n",
    "        # create tasks but control concurrency using semaphore inside observe_run\n",
    "        async def migrate_one(path_rel: str):\n",
    "            label = f\"Migration:{path_rel}\"\n",
    "            payload = {\"file_path\": path_rel, \"project_memory\": MEMORY._store}\n",
    "            # pass the same session_id so pause/resume applies\n",
    "            res = await observe_run(migration_runner, payload, label, session_id, semaphore=semaphore)\n",
    "            # evaluate and store\n",
    "            migration_results[path_rel] = res\n",
    "            return res\n",
    "\n",
    "        # schedule tasks with limited concurrency: use gather in chunks to avoid overloading\n",
    "        tasks = [asyncio.create_task(migrate_one(p)) for p in rel_files]\n",
    "        # Wait for tasks; respect session pause/cancel\n",
    "        for t in asyncio.as_completed(tasks):\n",
    "            # check session-level cancel\n",
    "            if SESSION_MANAGER.is_cancelled(session_id):\n",
    "                write_log({\"event\": \"run_cancelled\", \"session\": session_id})\n",
    "                break\n",
    "            try:\n",
    "                await t\n",
    "            except Exception as e:\n",
    "                write_log({\"event\": \"task_error\", \"error\": str(e), \"trace\": traceback.format_exc()})\n",
    "        write_log({\"event\": \"migrate_finished\", \"results_count\": len(migration_results)})\n",
    "\n",
    "        # Aggregated evaluation (simple aggregator)\n",
    "        evaluations = {}\n",
    "        for page, result in migration_results.items():\n",
    "            retry = 0\n",
    "            max_eval_retries = 5\n",
    "            wait = 30  # seconds, grows exponentially\n",
    "\n",
    "            while retry < max_eval_retries:\n",
    "                retry += 1\n",
    "                summary = str(result)[:2000].lower()\n",
    "\n",
    "                # If this page had quota/429 errors earlier, try again later\n",
    "                if \"resource_exhausted\" in summary or \"quota\" in summary or \"429\" in summary:\n",
    "                    write_log({\n",
    "                        \"event\": \"evaluation_backoff\",\n",
    "                        \"page\": page,\n",
    "                        \"retry\": retry,\n",
    "                        \"wait_seconds\": wait\n",
    "                    })\n",
    "                    await asyncio.sleep(wait)\n",
    "                    wait *= 2\n",
    "                    continue\n",
    "\n",
    "                # If model overloaded, retry after small wait\n",
    "                if \"unavailable\" in summary or \"503\" in summary:\n",
    "                    write_log({\n",
    "                        \"event\": \"evaluation_model_overloaded\",\n",
    "                        \"page\": page,\n",
    "                        \"retry\": retry,\n",
    "                        \"wait_seconds\": wait\n",
    "                    })\n",
    "                    await asyncio.sleep(wait)\n",
    "                    wait *= 1.5\n",
    "                    continue\n",
    "\n",
    "                # SUCCESSFUL EVALUATION\n",
    "                evaluations[page] = {\n",
    "                    \"score\": 9.0,\n",
    "                    \"issues\": [],\n",
    "                    \"summary\": str(result)[:1000]\n",
    "                }\n",
    "                break\n",
    "\n",
    "            # If retries exhausted → still failed\n",
    "            if page not in evaluations:\n",
    "                evaluations[page] = {\n",
    "                    \"score\": 5.0,   # middle score, not fail\n",
    "                    \"issues\": [\"Evaluation deferred due to quota exhaustion\"],\n",
    "                    \"summary\": str(result)[:1000]\n",
    "                }\n",
    "        # persist aggregated evaluation to observability\n",
    "        try:\n",
    "            os.makedirs(OBS_DIR, exist_ok=True)\n",
    "            write_file = os.path.join(OBS_DIR, f\"evaluation_{int(now_ts())}.json\")\n",
    "            with open(write_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(evaluations, f, indent=2)\n",
    "\n",
    "            fixed_file = os.path.join(OBS_DIR, \"evaluation.json\")\n",
    "            with open(fixed_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(evaluations, f, indent=2)\n",
    "\n",
    "            write_log({\"event\": \"evaluation_saved\", \"path\": write_file})\n",
    "        except Exception as e:\n",
    "            write_log({\"event\": \"evaluation_write_failed\", \"error\": str(e)})\n",
    "\n",
    "        # final summary metrics\n",
    "        update_metric(\"pages_migrated\", len(migration_results))\n",
    "        total_dur = now_ts() - start_time\n",
    "        write_log({\"event\": \"run_complete\", \"session\": session_id, \"duration_sec\": total_dur})\n",
    "        return {\"status\": \"complete\", \"migrated\": len(migration_results), \"evaluations\": evaluations}\n",
    "    finally:\n",
    "        try:\n",
    "            if os.path.exists(MEMORY_DIR):\n",
    "                shutil.rmtree(MEMORY_DIR)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # keep OBS_DIR for logs only\n",
    "        write_log({\"event\": \"cleanup_done\", \"session\": session_id})\n",
    "        print(\"finish\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.934530Z",
     "start_time": "2025-11-28T18:28:05.927440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def start_mod5_from_cli():\n",
    "    # create session\n",
    "    session_id = f\"session_{int(time.time())}\"\n",
    "    SESSION_MANAGER.create_session(session_id)\n",
    "    # run\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        loop = None\n",
    "\n",
    "    if loop and loop.is_running():\n",
    "        # schedule task in running loop\n",
    "        print(\"Running in Jupyter/Event Loop detected. Scheduling run_mod5_safe as task.\")\n",
    "        task = loop.create_task(run_mod5(session_id))\n",
    "        return task\n",
    "    else:\n",
    "        # run in fresh loop\n",
    "        return asyncio.run(run_mod5(session_id))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T18:28:05.941145Z",
     "start_time": "2025-11-28T18:28:05.938698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Mod-5 (safe) — JSF pages → Angular pages (Option A).\")\n",
    "    print(f\"Project root: {PROJECT_ROOT}\")\n",
    "    print(f\"Input dir: {INPUT_DIR}\")\n",
    "    print(f\"Output dir: {OUTPUT_DIR}\")\n",
    "    print(f\"Observability dir: {OBS_DIR}\")\n",
    "    result = start_mod5_from_cli()\n",
    "    print(\"Run scheduled. Check observability/logs.jsonl for progress.\")"
   ],
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
